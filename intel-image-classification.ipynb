{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "****"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Import The Necessary Libraries**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imageio\n",
    "\n",
    "from tqdm import tqdm\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-15T22:00:19.226832Z",
     "iopub.execute_input": "2022-12-15T22:00:19.227172Z",
     "iopub.status.idle": "2022-12-15T22:00:21.335066Z",
     "shell.execute_reply.started": "2022-12-15T22:00:19.227095Z",
     "shell.execute_reply": "2022-12-15T22:00:21.333964Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "use transforms to augment data and make it so the resnet model will be able to work with our images(thay must be of size 224)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "#     transforms.RandomRotation(degrees=(0, 180)),\n",
    "#     transforms.CenterCrop(size=224),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(size=256),\n",
    "    transforms.CenterCrop(size=224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder('/kaggle/input/intel-image-classification/seg_train/seg_train', transform=train_transform)\n",
    "test_dataset = datasets.ImageFolder('/kaggle/input/intel-image-classification/seg_test/seg_test', transform=test_transform)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-15T22:00:25.901497Z",
     "iopub.execute_input": "2022-12-15T22:00:25.902507Z",
     "iopub.status.idle": "2022-12-15T22:00:41.316975Z",
     "shell.execute_reply.started": "2022-12-15T22:00:25.902470Z",
     "shell.execute_reply": "2022-12-15T22:00:41.316008Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "load the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-15T22:00:45.127239Z",
     "iopub.execute_input": "2022-12-15T22:00:45.127605Z",
     "iopub.status.idle": "2022-12-15T22:00:45.132959Z",
     "shell.execute_reply.started": "2022-12-15T22:00:45.127575Z",
     "shell.execute_reply": "2022-12-15T22:00:45.131942Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "funcion defiend fo freezing and unfreezing our pre-trained model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def freeze_or_un_freeze(model ,val=False):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = val"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-15T22:00:49.936399Z",
     "iopub.execute_input": "2022-12-15T22:00:49.936774Z",
     "iopub.status.idle": "2022-12-15T22:00:49.941826Z",
     "shell.execute_reply.started": "2022-12-15T22:00:49.936743Z",
     "shell.execute_reply": "2022-12-15T22:00:49.940667Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "print(device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-15T22:00:51.993290Z",
     "iopub.execute_input": "2022-12-15T22:00:51.993689Z",
     "iopub.status.idle": "2022-12-15T22:00:51.999731Z",
     "shell.execute_reply.started": "2022-12-15T22:00:51.993653Z",
     "shell.execute_reply": "2022-12-15T22:00:51.998724Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": "cuda:0\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "defining our training and accuracy methods"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def accuracy(out, targets):\n",
    "    _, preds = torch.max(out, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == targets).item() / len(preds))\n",
    "\n",
    "def train(model, criterion, optimizer, train_loader, test_loader, epochs, unfreeze_after):\n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "    train_accs = np.zeros(epochs)\n",
    "    test_accs = np.zeros(epochs)\n",
    "    \n",
    "    for _ in tqdm(range(epochs)):\n",
    "        \n",
    "        if _ == unfreeze_after:\n",
    "            freeze_or_un_freeze(model, True)\n",
    "        \n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        test_acc = []\n",
    "        \n",
    "        model.train()\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            train_acc.append(accuracy(outputs, targets))\n",
    "        \n",
    "        train_loss = np.mean(train_loss)\n",
    "        train_acc = np.mean(train_acc)\n",
    "        \n",
    "        test_loss = []\n",
    "        \n",
    "        model.eval()\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_acc.append(accuracy(outputs, targets))\n",
    "\n",
    "            test_loss.append(loss.item())\n",
    "        test_loss = np.mean(test_loss)\n",
    "        test_acc = np.mean(test_acc)\n",
    "        \n",
    "        train_losses[_] = train_loss\n",
    "        test_losses[_] = test_loss\n",
    "        train_accs[_] = train_acc\n",
    "        test_accs[_] = test_acc\n",
    "        \n",
    "        print(f'Epoch {_+1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    return train_losses, test_losses, train_accs, test_accs"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-15T22:00:54.440209Z",
     "iopub.execute_input": "2022-12-15T22:00:54.440592Z",
     "iopub.status.idle": "2022-12-15T22:00:54.454273Z",
     "shell.execute_reply.started": "2022-12-15T22:00:54.440562Z",
     "shell.execute_reply": "2022-12-15T22:00:54.452308Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "model = models.resnet101(pretrained=True)\n",
    "print(model)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-13T17:04:01.746682Z",
     "iopub.execute_input": "2022-12-13T17:04:01.748519Z",
     "iopub.status.idle": "2022-12-13T17:04:02.758931Z",
     "shell.execute_reply.started": "2022-12-13T17:04:01.748482Z",
     "shell.execute_reply": "2022-12-13T17:04:02.756385Z"
    },
    "trusted": true
   },
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "text": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (6): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (7): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (8): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (9): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (10): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (11): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (12): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (13): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (14): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (15): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (16): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (17): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (18): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (19): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (20): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (21): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (22): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "freeze_or_un_freeze(model)\n",
    "n = model.fc.in_features\n",
    "print(n)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(n, 512), \n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, 6),\n",
    "    nn.Softmax(),\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-13T17:04:02.773114Z",
     "iopub.execute_input": "2022-12-13T17:04:02.773710Z",
     "iopub.status.idle": "2022-12-13T17:04:02.803142Z",
     "shell.execute_reply.started": "2022-12-13T17:04:02.773674Z",
     "shell.execute_reply": "2022-12-13T17:04:02.802225Z"
    },
    "trusted": true
   },
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "text": "2048\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, betas=(0, 0.999))\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-15T22:01:07.979514Z",
     "iopub.execute_input": "2022-12-15T22:01:07.979874Z",
     "iopub.status.idle": "2022-12-15T22:01:08.081694Z",
     "shell.execute_reply.started": "2022-12-15T22:01:07.979845Z",
     "shell.execute_reply": "2022-12-15T22:01:08.080206Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_23/579060358.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mcriterion\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCrossEntropyLoss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0moptimizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAdam\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.00001\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbetas\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0.999\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(device)\n",
    "model.to(device)\n",
    "train(model, criterion, optimizer, train_loader, test_loader, 30, 10)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-13T17:04:02.825481Z",
     "iopub.execute_input": "2022-12-13T17:04:02.827406Z",
     "iopub.status.idle": "2022-12-13T18:37:35.583192Z",
     "shell.execute_reply.started": "2022-12-13T17:04:02.827369Z",
     "shell.execute_reply": "2022-12-13T18:37:35.582165Z"
    },
    "trusted": true
   },
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "text": "cuda:0\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "  3%|▎         | 1/30 [01:56<56:14, 116.37s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 1, Train Loss: 1.6172, Test Loss: 1.3802, Train Acc: 0.6177, Test Acc: 0.8702\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "  7%|▋         | 2/30 [03:52<54:20, 116.46s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 2, Train Loss: 1.3577, Test Loss: 1.2465, Train Acc: 0.8546, Test Acc: 0.8865\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 10%|█         | 3/30 [05:48<52:19, 116.28s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 3, Train Loss: 1.2736, Test Loss: 1.2082, Train Acc: 0.8671, Test Acc: 0.8912\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 13%|█▎        | 4/30 [07:45<50:23, 116.27s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 4, Train Loss: 1.2385, Test Loss: 1.1901, Train Acc: 0.8751, Test Acc: 0.8922\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 17%|█▋        | 5/30 [09:41<48:28, 116.34s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 5, Train Loss: 1.2188, Test Loss: 1.1797, Train Acc: 0.8799, Test Acc: 0.8935\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 20%|██        | 6/30 [11:39<46:40, 116.68s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 6, Train Loss: 1.2089, Test Loss: 1.1737, Train Acc: 0.8771, Test Acc: 0.8958\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 23%|██▎       | 7/30 [13:37<44:57, 117.27s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 7, Train Loss: 1.1970, Test Loss: 1.1661, Train Acc: 0.8855, Test Acc: 0.9002\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 27%|██▋       | 8/30 [15:34<42:59, 117.26s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 8, Train Loss: 1.1902, Test Loss: 1.1608, Train Acc: 0.8890, Test Acc: 0.9031\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 30%|███       | 9/30 [17:33<41:13, 117.81s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 9, Train Loss: 1.1851, Test Loss: 1.1588, Train Acc: 0.8867, Test Acc: 0.9008\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 33%|███▎      | 10/30 [19:30<39:12, 117.60s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 10, Train Loss: 1.1792, Test Loss: 1.1579, Train Acc: 0.8920, Test Acc: 0.8988\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 37%|███▋      | 11/30 [23:13<47:26, 149.81s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 11, Train Loss: 1.1369, Test Loss: 1.1150, Train Acc: 0.9156, Test Acc: 0.9304\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 40%|████      | 12/30 [26:56<51:33, 171.88s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 12, Train Loss: 1.1116, Test Loss: 1.1095, Train Acc: 0.9366, Test Acc: 0.9351\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 43%|████▎     | 13/30 [30:39<53:06, 187.44s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 13, Train Loss: 1.1011, Test Loss: 1.1069, Train Acc: 0.9455, Test Acc: 0.9387\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 47%|████▋     | 14/30 [34:21<52:47, 197.96s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 14, Train Loss: 1.0919, Test Loss: 1.1058, Train Acc: 0.9550, Test Acc: 0.9384\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 50%|█████     | 15/30 [38:04<51:20, 205.35s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 15, Train Loss: 1.0863, Test Loss: 1.1157, Train Acc: 0.9593, Test Acc: 0.9293\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 53%|█████▎    | 16/30 [41:46<49:06, 210.47s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 16, Train Loss: 1.0839, Test Loss: 1.1045, Train Acc: 0.9621, Test Acc: 0.9384\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 57%|█████▋    | 17/30 [45:28<46:20, 213.91s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 17, Train Loss: 1.0787, Test Loss: 1.1091, Train Acc: 0.9671, Test Acc: 0.9325\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 60%|██████    | 18/30 [49:10<43:16, 216.37s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 18, Train Loss: 1.0743, Test Loss: 1.1090, Train Acc: 0.9712, Test Acc: 0.9341\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 63%|██████▎   | 19/30 [52:52<39:59, 218.10s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 19, Train Loss: 1.0728, Test Loss: 1.1066, Train Acc: 0.9726, Test Acc: 0.9366\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 67%|██████▋   | 20/30 [56:34<36:33, 219.38s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 20, Train Loss: 1.0697, Test Loss: 1.1072, Train Acc: 0.9756, Test Acc: 0.9377\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 70%|███████   | 21/30 [1:00:16<33:01, 220.14s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 21, Train Loss: 1.0699, Test Loss: 1.1052, Train Acc: 0.9757, Test Acc: 0.9387\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 73%|███████▎  | 22/30 [1:03:58<29:24, 220.61s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 22, Train Loss: 1.0665, Test Loss: 1.1035, Train Acc: 0.9792, Test Acc: 0.9399\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 77%|███████▋  | 23/30 [1:07:40<25:46, 220.92s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 23, Train Loss: 1.0661, Test Loss: 1.1063, Train Acc: 0.9788, Test Acc: 0.9393\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 80%|████████  | 24/30 [1:11:21<22:07, 221.17s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 24, Train Loss: 1.0634, Test Loss: 1.1044, Train Acc: 0.9819, Test Acc: 0.9379\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 83%|████████▎ | 25/30 [1:15:04<18:27, 221.44s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 25, Train Loss: 1.0620, Test Loss: 1.1042, Train Acc: 0.9829, Test Acc: 0.9399\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 87%|████████▋ | 26/30 [1:18:45<14:46, 221.59s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 26, Train Loss: 1.0606, Test Loss: 1.1035, Train Acc: 0.9841, Test Acc: 0.9399\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 90%|█████████ | 27/30 [1:22:27<11:04, 221.60s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 27, Train Loss: 1.0609, Test Loss: 1.1032, Train Acc: 0.9838, Test Acc: 0.9394\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 93%|█████████▎| 28/30 [1:26:09<07:23, 221.69s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 28, Train Loss: 1.0594, Test Loss: 1.1064, Train Acc: 0.9855, Test Acc: 0.9373\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 97%|█████████▋| 29/30 [1:29:51<03:41, 221.69s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 29, Train Loss: 1.0590, Test Loss: 1.1005, Train Acc: 0.9855, Test Acc: 0.9439\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "100%|██████████| 30/30 [1:33:32<00:00, 187.09s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 30, Train Loss: 1.0593, Test Loss: 1.1022, Train Acc: 0.9857, Test Acc: 0.9416\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "execution_count": 85,
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([1.61717532, 1.35768946, 1.27359237, 1.2385327 , 1.21877538,\n        1.20889992, 1.19702936, 1.19015058, 1.18506252, 1.17918133,\n        1.13691294, 1.11158177, 1.10106334, 1.09189397, 1.086268  ,\n        1.08385523, 1.07872464, 1.07425769, 1.07282956, 1.06966574,\n        1.06991312, 1.066483  , 1.06606211, 1.06335202, 1.06202542,\n        1.06063521, 1.06091288, 1.05944314, 1.05898595, 1.05925425]),\n array([1.38019052, 1.2465365 , 1.20815468, 1.19006454, 1.17972906,\n        1.17374684, 1.16606487, 1.16080782, 1.15881382, 1.15790578,\n        1.11502724, 1.10950824, 1.10686472, 1.10578779, 1.11566602,\n        1.1045071 , 1.10909968, 1.10904689, 1.10660654, 1.10721463,\n        1.10522882, 1.1035242 , 1.10633563, 1.10443056, 1.10415704,\n        1.10346321, 1.10322707, 1.10644639, 1.10048554, 1.10222687]),\n array([0.61769962, 0.85457796, 0.86714602, 0.87506324, 0.87985641,\n        0.87705642, 0.88552737, 0.88903922, 0.88666636, 0.89198941,\n        0.91555148, 0.93660623, 0.94554383, 0.95501137, 0.95929831,\n        0.96214569, 0.96711278, 0.97117025, 0.97259396, 0.97559959,\n        0.97574192, 0.97921413, 0.978787  , 0.98191911, 0.98294735,\n        0.98405468, 0.98384112, 0.98547834, 0.98554957, 0.98569191]),\n array([0.87023497, 0.88652486, 0.89117908, 0.89217645, 0.89350623,\n        0.89583337, 0.90015519, 0.90314716, 0.90082008, 0.89882541,\n        0.93040782, 0.93506211, 0.93871897, 0.93838656, 0.92929959,\n        0.93838656, 0.9325133 , 0.93406475, 0.93661344, 0.93772167,\n        0.93871897, 0.93993789, 0.939273  , 0.93794322, 0.93993789,\n        0.93993789, 0.93938386, 0.93727833, 0.94392729, 0.94160014]))"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_losses=[]\n",
    "test_losses=[]\n",
    "def accuracy_final(loader, model):\n",
    "    num_corrects = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    loop = tqdm(loader)\n",
    "    with torch.no_grad():\n",
    "        for x, y in loop:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            scores = model(x)\n",
    "            test_losses.append(scores.data)\n",
    "            _, prediction = scores.max(1)\n",
    "            num_corrects += (prediction == y).sum()\n",
    "            num_samples += prediction.size(0)\n",
    "            acc = (num_corrects/num_samples) * 100\n",
    "            loop.set_postfix(acc=acc.item())\n",
    "        print(f'Got {num_corrects}/{num_samples} with accuracy {acc:.4f}')\n",
    "\n",
    "accuracy_mehrdad(test_loader, model)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-13T18:45:10.161690Z",
     "iopub.execute_input": "2022-12-13T18:45:10.162066Z",
     "iopub.status.idle": "2022-12-13T18:45:28.317978Z",
     "shell.execute_reply.started": "2022-12-13T18:45:10.162034Z",
     "shell.execute_reply": "2022-12-13T18:45:28.316874Z"
    },
    "trusted": true
   },
   "execution_count": 87,
   "outputs": [
    {
     "name": "stderr",
     "text": "100%|██████████| 94/94 [00:18<00:00,  5.18it/s, acc=94.2]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Got 2825/3000 with accuracy 94.1667\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "lets try another aproach"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "model = models.resnet152(pretrained=True)\n",
    "print(model)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-15T22:03:01.820738Z",
     "iopub.execute_input": "2022-12-15T22:03:01.821296Z",
     "iopub.status.idle": "2022-12-15T22:03:03.131932Z",
     "shell.execute_reply.started": "2022-12-15T22:03:01.821253Z",
     "shell.execute_reply": "2022-12-15T22:03:03.130966Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (6): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (7): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (6): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (7): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (8): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (9): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (10): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (11): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (12): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (13): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (14): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (15): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (16): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (17): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (18): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (19): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (20): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (21): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (22): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (23): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (24): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (25): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (26): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (27): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (28): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (29): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (30): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (31): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (32): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (33): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (34): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (35): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = models.resnet152(pretrained=True)\n",
    "print(model)\n",
    "freeze_or_un_freeze(model)\n",
    "n = model.fc.in_features\n",
    "print(n)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(n, 512), \n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, 6),\n",
    "    nn.Softmax(),\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, betas=(0, 0.999))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-15T22:03:10.014791Z",
     "iopub.execute_input": "2022-12-15T22:03:10.015161Z",
     "iopub.status.idle": "2022-12-15T22:03:10.049438Z",
     "shell.execute_reply.started": "2022-12-15T22:03:10.015130Z",
     "shell.execute_reply": "2022-12-15T22:03:10.048398Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": "2048\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.to(device)\n",
    "train(model, criterion, optimizer, train_loader, test_loader, 30, 10)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-15T22:03:12.468236Z",
     "iopub.execute_input": "2022-12-15T22:03:12.468594Z",
     "iopub.status.idle": "2022-12-16T00:07:53.798396Z",
     "shell.execute_reply.started": "2022-12-15T22:03:12.468564Z",
     "shell.execute_reply": "2022-12-16T00:07:53.797317Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "text": "  3%|▎         | 1/30 [03:27<1:40:03, 207.02s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 1, Train Loss: 1.6215, Test Loss: 1.3869, Train Acc: 0.6249, Test Acc: 0.8756\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "  7%|▋         | 2/30 [05:49<1:18:53, 169.04s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 2, Train Loss: 1.3674, Test Loss: 1.2564, Train Acc: 0.8492, Test Acc: 0.8789\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 10%|█         | 3/30 [08:11<1:10:28, 156.60s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 3, Train Loss: 1.2830, Test Loss: 1.2129, Train Acc: 0.8640, Test Acc: 0.8875\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 13%|█▎        | 4/30 [10:33<1:05:26, 151.01s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 4, Train Loss: 1.2443, Test Loss: 1.1946, Train Acc: 0.8749, Test Acc: 0.8882\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 17%|█▋        | 5/30 [12:55<1:01:30, 147.64s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 5, Train Loss: 1.2247, Test Loss: 1.1828, Train Acc: 0.8752, Test Acc: 0.8932\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 20%|██        | 6/30 [15:17<58:19, 145.82s/it]  ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 6, Train Loss: 1.2090, Test Loss: 1.1755, Train Acc: 0.8836, Test Acc: 0.8925\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 23%|██▎       | 7/30 [17:39<55:23, 144.50s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 7, Train Loss: 1.1989, Test Loss: 1.1716, Train Acc: 0.8867, Test Acc: 0.8915\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 27%|██▋       | 8/30 [20:01<52:45, 143.87s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 8, Train Loss: 1.1926, Test Loss: 1.1660, Train Acc: 0.8892, Test Acc: 0.8952\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 30%|███       | 9/30 [22:23<50:07, 143.21s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 9, Train Loss: 1.1865, Test Loss: 1.1620, Train Acc: 0.8891, Test Acc: 0.8948\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 33%|███▎      | 10/30 [24:45<47:32, 142.62s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 10, Train Loss: 1.1825, Test Loss: 1.1583, Train Acc: 0.8887, Test Acc: 0.8998\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 37%|███▋      | 11/30 [29:44<1:00:23, 190.71s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 11, Train Loss: 1.1404, Test Loss: 1.1120, Train Acc: 0.9122, Test Acc: 0.9341\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 40%|████      | 12/30 [34:43<1:07:06, 223.69s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 12, Train Loss: 1.1097, Test Loss: 1.1063, Train Acc: 0.9376, Test Acc: 0.9382\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 43%|████▎     | 13/30 [39:43<1:09:55, 246.77s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 13, Train Loss: 1.0982, Test Loss: 1.1016, Train Acc: 0.9495, Test Acc: 0.9437\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 47%|████▋     | 14/30 [44:43<1:10:05, 262.87s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 14, Train Loss: 1.0912, Test Loss: 1.1064, Train Acc: 0.9553, Test Acc: 0.9356\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 50%|█████     | 15/30 [49:43<1:08:31, 274.07s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 15, Train Loss: 1.0869, Test Loss: 1.1057, Train Acc: 0.9599, Test Acc: 0.9385\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 53%|█████▎    | 16/30 [54:43<1:05:43, 281.66s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 16, Train Loss: 1.0813, Test Loss: 1.1049, Train Acc: 0.9645, Test Acc: 0.9384\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 57%|█████▋    | 17/30 [59:42<1:02:11, 287.07s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 17, Train Loss: 1.0745, Test Loss: 1.1063, Train Acc: 0.9714, Test Acc: 0.9382\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 60%|██████    | 18/30 [1:04:42<58:09, 290.80s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 18, Train Loss: 1.0726, Test Loss: 1.1042, Train Acc: 0.9725, Test Acc: 0.9402\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 63%|██████▎   | 19/30 [1:09:42<53:49, 293.55s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 19, Train Loss: 1.0714, Test Loss: 1.1025, Train Acc: 0.9737, Test Acc: 0.9432\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 67%|██████▋   | 20/30 [1:14:42<49:14, 295.43s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 20, Train Loss: 1.0679, Test Loss: 1.1033, Train Acc: 0.9774, Test Acc: 0.9415\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 70%|███████   | 21/30 [1:19:41<44:30, 296.78s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 21, Train Loss: 1.0664, Test Loss: 1.1053, Train Acc: 0.9785, Test Acc: 0.9394\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 73%|███████▎  | 22/30 [1:24:41<39:41, 297.70s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 22, Train Loss: 1.0647, Test Loss: 1.1041, Train Acc: 0.9801, Test Acc: 0.9384\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 77%|███████▋  | 23/30 [1:29:41<34:48, 298.30s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 23, Train Loss: 1.0640, Test Loss: 1.1065, Train Acc: 0.9809, Test Acc: 0.9354\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 80%|████████  | 24/30 [1:34:42<29:54, 299.11s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 24, Train Loss: 1.0624, Test Loss: 1.1017, Train Acc: 0.9826, Test Acc: 0.9410\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 83%|████████▎ | 25/30 [1:39:43<24:57, 299.53s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 25, Train Loss: 1.0604, Test Loss: 1.1006, Train Acc: 0.9844, Test Acc: 0.9433\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 87%|████████▋ | 26/30 [1:44:43<19:58, 299.69s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 26, Train Loss: 1.0603, Test Loss: 1.1012, Train Acc: 0.9842, Test Acc: 0.9432\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 90%|█████████ | 27/30 [1:49:42<14:58, 299.48s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 27, Train Loss: 1.0608, Test Loss: 1.1100, Train Acc: 0.9836, Test Acc: 0.9357\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 93%|█████████▎| 28/30 [1:54:41<09:59, 299.50s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 28, Train Loss: 1.0594, Test Loss: 1.1033, Train Acc: 0.9846, Test Acc: 0.9429\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 97%|█████████▋| 29/30 [1:59:41<04:59, 299.50s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 29, Train Loss: 1.0589, Test Loss: 1.1058, Train Acc: 0.9858, Test Acc: 0.9366\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "100%|██████████| 30/30 [2:04:41<00:00, 249.37s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 30, Train Loss: 1.0587, Test Loss: 1.1071, Train Acc: 0.9855, Test Acc: 0.9381\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "execution_count": 15,
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([1.62154042, 1.36742133, 1.28303813, 1.24429846, 1.22469136,\n        1.20899252, 1.19890135, 1.19259588, 1.18652643, 1.18252647,\n        1.14035904, 1.10974678, 1.09822216, 1.09121622, 1.08685227,\n        1.08126099, 1.07449165, 1.07263337, 1.07144574, 1.06793341,\n        1.06637014, 1.06471122, 1.06400162, 1.06236949, 1.06044867,\n        1.06034315, 1.06081196, 1.05937214, 1.05887232, 1.05869326]),\n array([1.38694091, 1.25638575, 1.21290524, 1.1946052 , 1.18283801,\n        1.17552867, 1.17157473, 1.16601787, 1.16201164, 1.15831631,\n        1.11196652, 1.10633051, 1.10159806, 1.10636146, 1.10570289,\n        1.10486785, 1.1062826 , 1.10418904, 1.10251463, 1.1032901 ,\n        1.10529004, 1.10408998, 1.10651004, 1.10174267, 1.10064325,\n        1.101247  , 1.11004928, 1.10328191, 1.10581246, 1.10712837]),\n array([0.62493676, 0.84924704, 0.86397433, 0.87490511, 0.87517399,\n        0.8836292 , 0.88673753, 0.8891657 , 0.88907081, 0.88873863,\n        0.91224533, 0.93758702, 0.94945902, 0.95525658, 0.95989943,\n        0.96451056, 0.97138381, 0.97246742, 0.97373289, 0.97736335,\n        0.97851813, 0.98013949, 0.98086721, 0.98264682, 0.98441058,\n        0.98419702, 0.98364341, 0.98462415, 0.98577893, 0.98547834]),\n array([0.87555408, 0.87887859, 0.88752216, 0.88818711, 0.89317381,\n        0.89250886, 0.89151156, 0.89516848, 0.89483601, 0.89982271,\n        0.93406475, 0.93816489, 0.94370568, 0.93561614, 0.93849736,\n        0.93838656, 0.93816489, 0.94015956, 0.94315159, 0.94148934,\n        0.93938386, 0.93838656, 0.93539453, 0.94104612, 0.9432624 ,\n        0.94315159, 0.935727  , 0.94292992, 0.93661344, 0.93805408]))"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "okay this got worse so lets not use this aproach and lets stick to our first model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "by the way sorry for not plotting the loss and accuracy on epoch i forgot to take the return and well now its too latr"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train(model, criterion, optimizer, train_loader, test_loader, 15, 5)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-16T00:08:35.058475Z",
     "iopub.execute_input": "2022-12-16T00:08:35.059189Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "  7%|▋         | 1/15 [04:59<1:09:48, 299.18s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 1, Train Loss: 1.0578, Test Loss: 1.1083, Train Acc: 0.9866, Test Acc: 0.9342\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 13%|█▎        | 2/15 [09:58<1:04:54, 299.54s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 2, Train Loss: 1.0571, Test Loss: 1.1038, Train Acc: 0.9873, Test Acc: 0.9387\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 20%|██        | 3/15 [14:58<59:55, 299.65s/it]  ",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 3, Train Loss: 1.0561, Test Loss: 1.1032, Train Acc: 0.9881, Test Acc: 0.9419\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 27%|██▋       | 4/15 [19:58<54:54, 299.51s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 4, Train Loss: 1.0571, Test Loss: 1.1064, Train Acc: 0.9870, Test Acc: 0.9369\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": " 33%|███▎      | 5/15 [24:57<49:55, 299.51s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 5, Train Loss: 1.0573, Test Loss: 1.1106, Train Acc: 0.9867, Test Acc: 0.9328\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model2 = models.resnet34(pretrained=True)\n",
    "print(model2)\n",
    "freeze_or_un_freeze(model2)\n",
    "n = model2.fc.in_features\n",
    "print(n)\n",
    "model2.fc = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(n, 512), \n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, 6),\n",
    "    nn.Softmax(),\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.00001, betas=(0, 0.999))\n",
    "train(model, criterion, optimizer, train_loader, test_loader, 30, 10)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}